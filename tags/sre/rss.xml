<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>sre on Log4D</title>
    <link>https://blog.alswl.com/tags/sre/</link>
    <description>Recent content in sre on Log4D</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 09 Sep 2018 23:21:40 +0800</lastBuildDate><atom:link href="https://blog.alswl.com/tags/sre/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DevOps 和 SRE</title>
      <link>https://blog.alswl.com/2018/09/devops-and-sre/</link>
      <pubDate>Sun, 09 Sep 2018 23:21:40 +0800</pubDate>
      
      <guid>https://blog.alswl.com/2018/09/devops-and-sre/</guid>
      <description>最近有一位朋友和我聊职业发展方向问题，聊了不少 DevOps 和 SRE 话题。 我几年前刚接触这两个概念时也常常将之混淆，可惜当时没有人来解答我困惑。 现在这虽然已经极为流行，但是我发现我这位朋友对这两个职位还存在一些误区。 于是我给了一些见解并整理成文章以饕大众。 最常见的误区： DevOps 新概念，好高级哦 SRE 是高级版 DevOps 运维可以轻松转身 DevOps 工程师 让我一一给你讲解吧。 image via YouTube DevOps 和 SRE 定义 DevOps 是字面上 Dev 开发 / Ops 运维两者组合， 严格意义上 DevOps 如下（vi</description>
      <content:encoded><![CDATA[<p>最近有一位朋友和我聊职业发展方向问题，聊了不少 DevOps 和 SRE 话题。
我几年前刚接触这两个概念时也常常将之混淆，可惜当时没有人来解答我困惑。
现在这虽然已经极为流行，但是我发现我这位朋友对这两个职位还存在一些误区。
于是我给了一些见解并整理成文章以饕大众。</p>
<p>最常见的误区：</p>
<ul>
<li>DevOps 新概念，好高级哦</li>
<li>SRE 是高级版 DevOps</li>
<li>运维可以轻松转身 DevOps 工程师</li>
</ul>
<p>让我一一给你讲解吧。</p>
<p>




<img loading="lazy" src="https://e25ba8-log4d-c.dijingchao.com/images/upload_dropbox/201809/sre-and-devops.png" alt="sre-and-devops.png"  />



<small><a href="https://www.youtube.com/watch?v=uTEL8Ff1Zvk">image via YouTube</a></small></p>
<!-- more -->
<h2 id="devops-和-sre-定义">DevOps 和 SRE 定义</h2>
<p>DevOps 是字面上 Dev 开发 / Ops 运维两者组合，
严格意义上 DevOps 如下（via <a href="https://en.wikipedia.org/wiki/DevOps">DevOps - Wikipedia</a>）：</p>
<blockquote>
<p>DevOps（Development 和 Operations 的组合词）是一种重视“软件开发人员（Dev）
”和“IT 运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。</p>
</blockquote>
<p>SRE 全称是 Site Reliability Engineering，最早是由 Google 提出，并且在其工程实践中发扬光大。
他们还出了一本同名书籍「<a href="https://landing.google.com/sre/book.html">Site Reliability Engineering</a>」，
让这个理念在互联网工程师圈子里广泛传播。</p>
<p>Google 对 SRE 解释是（via <a href="https://en.wikipedia.org/wiki/Site_Reliability_Engineering">Site Reliability Engineering - Wikipedia</a>）：</p>
<blockquote>
<p>Site reliability engineering (SRE) is a discipline that incorporates aspects of
software engineering and applies that to operations whose goals are to
create ultra-scalable and highly reliable software systems.</p>
</blockquote>
<p>我将其翻译翻译为中文：</p>
<blockquote>
<p>网站稳定性工程师是致力于打造「高扩展、高可用系统」，并将其贯彻为原则的软件工程师。</p>
</blockquote>
<p>从定义来看，DevOps 是文化、运动和惯例，而 SRE 是有严格任职要求的职位。
文化是软性定义，文化有更多概念可以捏造，而 SRE 定义精准，就少了想象空间（也可能 SRE 门槛高 😄）。
按 Google 给出的说法是，SRE 工程师实践了 DevOps 文化。这个观点没错，但是国内的 DevOps 逐步独立出 DevOps 工程师，
所以在本文，我着重讨论的是 DevOps 工程师和 SRE 工程师两种职位对比。</p>
<h2 id="两者产生背景和历史">两者产生背景和历史</h2>
<p>互联网需求催生了 DevOps 。在最传统软件企业中，是只有 Dev 没有 Ops，
那时 Ops 可能还是只是技术支持人员。开发按照瀑布流：需求分析、系统设计、开发、测试、交付、运行，
传统软件发布是一个重量级操作。一旦发布，Dev 几乎不再直接操作。
80 后可能会记得 QQ 每年都会有一个大版本发布吧，QQ 2000 / 2003 / 2004 等等。
此时 Ops 不用和 Dev 直接高频接触，甚至针对一些纯离线业务，压根没有设立 Ops 这个岗位。</p>
<p>




<img loading="lazy" src="https://e25ba8-log4d-c.dijingchao.com/images/upload_dropbox/201809/qq-2004.png" alt="qq-2004.png"  />


</p>
<p>互联网浪潮之后，软件由传统意义上桌面软件演变为面向网站、手机应用。
这时候业务核心逻辑，比如交易，社交行为都不在用户桌面完成，而是在服务器后端完成。
这给互联网企业给予了极大操作空间：随时可以改变业务逻辑，这促进了业务快速迭代变更。
但即便这样，Dev 和 Ops 是极其分裂的两个环节。Ops 不关心代码是如何运作的，Dev 不知道代码如何运行在服务器上。</p>
<p>当业界还沉浸在可以每周发布版本喜悦中时，2009 年，Flicker 提出了每天发布 10+ 次概念，大大震撼了业界。
Flicker 提出了几个核心理念：</p>
<ul>
<li>业务快速发展，需要拥抱变更，小步快跑</li>
<li>Ops 目标不是为了网站稳定和快速，而是推动业务快速发展</li>
<li>基于自动化工具提高 Dev / Ops 联接：代码版本管理、监控</li>
<li>高效沟通：IRC / IM Robot（现在那些 ChatBot 套路，10 年前就被 Flicker 玩过了）</li>
<li>信任、透明、高效、互助的沟通文化</li>
</ul>
<p>




<img loading="lazy" src="https://e25ba8-log4d-c.dijingchao.com/images/upload_dropbox/201809/flicker.png" alt="flicker.png"  />


</p>
<p>原文 SlideShare 在这
<a href="https://www.slideshare.net/jallspaw/10-deploys-per-day-dev-and-ops-cooperation-at-flickr">10+ Deploys Per Day: Dev and Ops Cooperation at Flickr</a></p>
<p>真是让人难以想象，今天各种培训公司和一些知名大 V 在呼唤这些 DevOps 理念，
竟然在 2009 年一份幻灯片中就展现淋漓尽致。经典总是不过时，在尘封下闪耀着智慧光芒。
有些人将 DevOps 和运维自动化等同，这是只看到表象。
DevOps 目标是提高业务系统交付速度，并为之提供相关工具、制度和服务。
一些个人或培训机构添油加醋和衍生含义，都是围绕这 DevOps 本质而发散。</p>
<p>接下来聊聊 SRE 历史， SRE 出现要晚一些。在 2003 年时候 Google 的 Ben Treynor
招募了几个软件工程师，这个团队设立目的是帮助 Google 生产环境服务运行更稳定、健壮、可靠。
不同于中小型规模公司，Google 服务于十几亿用户服务，短暂服务不可用会带来致命后果。
因此 Google 走在了时代最前面，SRE 产生了。</p>
<p>这个职位为大规模集群服务，小型团队不需要这样职位设定（可能也招不起真正 SRE 😊）。
Google 在探索若干年之后，SRE 团队开始将自己心得体会写在线上，并在 2016 年将此书出版。</p>
<h2 id="两者的职能不同">两者的职能不同</h2>
<p>DevOps 文化，那么就没有一个具象职能要求。现在不少公司将 DevOps 职能单独抽取出来，称之为 DevOps 工程师。
那让我们看看 DevOps 工程师关心什么：DevOps 文化目的是提交交付速度， DevOps 工程师就自然会关心软件 / 服务的整个生命周期。</p>
<p>一个简单的公式：<code>速度 = 总量 / 时间</code>，添上工程行业术语，即 <code>交付速度 = （（功能特性 * 工程质量） / 交付时间） * 交付风险</code>。</p>
<p>功能特性交给产品经理和项目经理管理，DevOps 工程师需要关心剩下几个因素：工程质量 / 交付时间 / 交付风险。
DevOps 工程师职能如下：</p>
<ul>
<li>管理应用全生命周期（需求、设计、开发、QA、发布、运行）</li>
<li>关注全流程效率提升，挖掘瓶颈点并将其解决</li>
<li>自动化运维平台设计和研发工作（标准化、自动化、平台化）</li>
<li>支持运维系统，包括 虚拟化技术、资源管理技术、监控技术、网络技术</li>
</ul>
<p>SRE 关键词是「高扩展性」「高可用性」。高扩展性是指当服务用户数量暴增时，
应用系统以及支撑其服务（服务器资源、网络系统、数据库资源）可以在不调整系统结构，不强化机器本身性能
，仅仅增加实例数量方式进行扩容。高可用性是指，应用架构中任何环节出现不可用时，比如应用服务、网关、数据库
等系统挂掉，整个系统可以在可预见时间内恢复并重新提供服务。当然，既然是「高」可用，
那么这个时间一般期望在分钟级别。SRE 职能可以概括为以下：</p>
<ul>
<li>为 应用、中间件、基础设施等提供 选型、设计、开发、容量规划、调优、故障处理</li>
<li>为业务系统提供基于可用性、可扩展性考虑决策，参与业务系统设计和实施</li>
<li>定位、处理、管理故障，优化导致故障发生相关部件</li>
<li>提高各部件资源利用率</li>
</ul>
<h2 id="工作内容不同">工作内容不同</h2>
<p>职责不同导致两个职位工作内容也不尽相同，我将 DevOps 工程师和 SRE 工程师职能列举如下：</p>
<ul>
<li>DevOps
<ul>
<li>设定应用生命管理周期制度，扭转流程</li>
<li>开发、管理 开发工程师 /QA 工程师使用 开发平台系统</li>
<li>开发、管理 发布系统</li>
<li>开发、选型、管理 监控、报警系统</li>
<li>开发、管理 权限系统</li>
<li>开发、选型、管理 CMBD</li>
<li>管理变更</li>
<li>管理故障</li>
</ul>
</li>
<li>SRE
<ul>
<li>管理变更</li>
<li>管理故障</li>
<li>制定 SLA 服务标准</li>
<li>开发、选型、管理 各类中间件</li>
<li>开发、管理 分布式监控系统</li>
<li>开发、管理 分布式追踪系统</li>
<li>开发、管理 性能监控、探测系统（dtrace、火焰图）</li>
<li>开发、选型、培训 性能调优工具</li>
</ul>
</li>
</ul>
<p>很有趣的对比，DevOps 和 SRE 都会关心应用生命周期，特别是生命周期里面中变更和故障。
但是 DevOps 工作内容是主要为开发链路服务，一个 DevOps Team 通常会提供一串工具链，
这其中会包括：开发工具、版本管理工具、CI 持续交付工具、CD 持续发布工具、报警工具、故障处理。
而 SRE Team 则关注更为关注变更、故障、性能、容量相关问题，会涉及具体业务，产出工具链会有：
容量测量工具、Logging 日志工具、Tracing 调用链路跟踪工具、Metrics 性能度量工具、监控报警工具等。</p>
<h2 id="devops-和-sre-关系">DevOps 和 SRE 关系</h2>
<p>DevOps 首先是一种文化，后期逐渐独立成一个职位；SRE 一开始就明确是一个职位；
不少同学把 DevOps 和 SRE 搞混，是被两者表象锁迷惑，看上去这两者都有的工具属性、自动化要求也相似。
甚至有一些开发同学把这类运维工作都统一理解为：服务器 + 工具 + 自动化。这是盲人摸象，管中窥豹。</p>
<p>从技能上来说，两者都需要较强的运维技能。
在职业发展天花板上，DevOps 可能缺乏 SRE 在一些专业领域的技能：
计算机体系结构能力；高吞吐高并发优化能力；可扩展系统设计能力；复杂系统设计能力；业务系统排查能力。
两者都需要软实力，但是 SRE 面临复杂度更高，挑战更大，要求也更高：</p>
<ul>
<li>分析问题、解决问题能力</li>
<li>对业务系统更了解</li>
<li>具备高并发、高可用系统设计实施经验</li>
<li>对整个系统链路有更全面认识</li>
</ul>
<p>DevOps 具有普遍意义，现代互联网公司都需要 DevOps，但是并非所有团队对高可用性、高扩展性存在需求，它们不需要 SRE。
DevOps 工程师掌握相关技能之后，也有机会可以发展为 SRE 工程师。
而一位合格 SRE 工程师，在有选择情况下面，我相信不会去转型为 DevOps 工程师。</p>
<p>从专业背景来看，无论是 DevOps 还是 SRE 工程师，都需要研发背景，前者需要开发工具链，后者需要有较强架构设计经验。
如果有运维工程师想转型成为 DevOps 或者 SRE，那么需要补上相关技术知识。
毕竟，不是会搭建一套 Jenkins + Kubernetes 就可以自称为 DevOps / SRE 工程师。</p>
<p>怎么样，有没有解开这几个常见误区呢？希望你看到这里可以豁然开朗，最后附上两个工程师的技能点，
期望有志成为这两种工程师的同学，加油努力。</p>
<h2 id="附录技能点">附录：技能点</h2>
<p>DevOps：</p>
<ul>
<li>Operator 技能
<ul>
<li>Linux Basis
<ul>
<li>基本命令操作</li>
<li>Linux FHS（Filesystem Hierarchy Standard 文件系统层次结构标准）</li>
<li>Linux 系统（差异、历史、标准、发展）</li>
</ul>
</li>
<li>脚本
<ul>
<li>Bash / Python</li>
</ul>
</li>
<li>基础服务
<ul>
<li>DHCP / NTP / DNS / SSH / iptables / LDAP / CMDB</li>
</ul>
</li>
<li>自动化工具
<ul>
<li>Fabric / Saltstack / Chef / Ansible</li>
</ul>
</li>
<li>基础监控工具
<ul>
<li>Zabbix / Nagios / Cacti</li>
</ul>
</li>
<li>虚拟化
<ul>
<li>KVM 管理 / XEN 管理 / vSphere 管理 / Docker</li>
<li>容器编排 / Mesos / Kubernetes</li>
</ul>
</li>
<li>服务
<ul>
<li>Nginx / F5 / HAProxy / LVS 负载均衡</li>
<li>常见中间件 Operate（启动、关闭、重启、扩容）</li>
</ul>
</li>
</ul>
</li>
<li>Dev
<ul>
<li>语言
<ul>
<li>Python</li>
<li>Go（可选）</li>
<li>Java（了解部署）</li>
</ul>
</li>
<li>流程和理论
<ul>
<li>Application Life Cycle</li>
<li>12 Factor</li>
<li>微服务概念、部署、生命周期</li>
<li>CI 持续集成 / Jenkins / Pipeline / Git Repo Web Hook</li>
<li>CD 持续发布系统</li>
</ul>
</li>
<li>基础设施
<ul>
<li>Git Repo / Gitlab / Github</li>
<li>Logstash / Flume 日志收集</li>
<li>配置文件管理（应用、中间件等）</li>
<li>Nexus / JFrog / Pypi 包依赖管理</li>
<li>面向 开发 / QA 开发环境管理系统</li>
<li>线上权限分配系统</li>
<li>监控报警系统</li>
<li>基于 Fabric / Saltstack / Chef / Ansible 自动化工具开发</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>SRE：</p>
<ul>
<li>语言和工程实现
<ul>
<li>深入理解开发语言（假设是 Java）
<ul>
<li>业务部门使用开发框架</li>
<li>并发、多线程和锁</li>
<li>资源模型理解：网络、内存、CPU</li>
<li>故障处理能力（分析瓶颈、熟悉相关工具、还原现场、提供方案）</li>
</ul>
</li>
<li>常见业务设计方案和陷阱（比如 Business Modeling，N+1、远程调用、不合理 DB 结构）</li>
<li>MySQL / Mongo OLTP 类型查询优化</li>
<li>多种并发模型，以及相关 Scalable 设计</li>
</ul>
</li>
<li>问题定位工具
<ul>
<li>容量管理</li>
<li>Tracing 链路追踪</li>
<li>Metrics 度量工具</li>
<li>Logging 日志系统</li>
</ul>
</li>
<li>运维架构能力
<ul>
<li>Linux 精通，理解 Linux 负载模型，资源模型</li>
<li>熟悉常规中间件（MySQL Nginx Redis Mongo ZooKeeper 等），能够调优</li>
<li>Linux 网络调优，网络 IO 模型以及在语言里面实现</li>
<li>资源编排系统（Mesos / Kubernetes）</li>
</ul>
</li>
<li>理论
<ul>
<li>容量规划方案</li>
<li>熟悉分布式理论（Paxos / Raft / BigTable / MapReduce / Spanner 等），能够为场景决策合适方案</li>
<li>性能模型（比如 Pxx 理解、Metrics、Dapper）</li>
<li>资源模型（比如 Queuing Theory、负载方案、雪崩问题）</li>
<li>资源编排系统（Mesos / Kurbernetes）</li>
</ul>
</li>
</ul>
<h2 id="ref">Ref</h2>
<ul>
<li><a href="https://zh.wikipedia.org/wiki/DevOps">DevOps - 维基百科，自由的百科全书</a></li>
<li><a href="https://en.wikipedia.org/wiki/Site_reliability_engineering">Site reliability engineering - Wikipedia</a></li>
<li><a href="http://skill-map.stuq.org/">StuQ 技能图谱</a></li>
<li><a href="https://12factor.net/zh_cn/">The Twelve-Factor App （简体中文）</a></li>
<li><a href="https://landing.google.com/sre/book/chapters/communication-and-collaboration.html">Google - Site Reliability Engineering</a></li>
<li><a href="https://www.youtube.com/watch?v=uTEL8Ff1Zvk">What&rsquo;s the Difference Between DevOps and SRE? - YouTube</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>搞定暴涨的流量</title>
      <link>https://blog.alswl.com/2016/06/capacity-planning/</link>
      <pubDate>Sun, 19 Jun 2016 23:57:39 +0800</pubDate>
      
      <guid>https://blog.alswl.com/2016/06/capacity-planning/</guid>
      <description>2013 年左右，我司业务发展迅速，每天晚上都会面临服务器濒临崩溃情况。 我相信每个高速发展的互联网企业在某个阶段都会面临这样的情形，比如去年爆红的「足迹」。 过程往往是：线上出现故障，手机会收到报警，然后登录到服务器上去解决问题。 处理这种问题工种现在有一个时髦的名称，叫做「SRE（Site Reliability Engineer）」系统可用性工程师。 虽然我常常救火，但是我还是想尽可能避免线上发生故障。「最好的消息，就是没有消息。</description>
      <content:encoded><![CDATA[<p>2013 年左右，我司业务发展迅速，每天晚上都会面临服务器濒临崩溃情况。
我相信每个高速发展的互联网企业在某个阶段都会面临这样的情形，比如去年爆红的「足迹」。
过程往往是：线上出现故障，手机会收到报警，然后登录到服务器上去解决问题。
处理这种问题工种现在有一个时髦的名称，叫做「SRE（Site Reliability Engineer）」系统可用性工程师。</p>
<p>虽然我常常救火，但是我还是想尽可能避免线上发生故障。「最好的消息，就是没有消息。」
减少故障出现概率，增强系统可用性，降低故障处理时间是 SRE 的最大课题。
在这里有最常用的两个手段，一个是优化性能，一个是做好容量规划和扩展。
这里我着重讨论后者「容量规划」。</p>
<p>




<img loading="lazy" src="https://e25ba8-log4d-c.dijingchao.com/images/upload_dropbox/201606/message.png" alt="看我的一堆报警消息"  />


</p>
<p>^ 看我的一堆报警消息</p>
<!-- more -->
<h2 id="面临的问题">面临的问题</h2>
<p>面对暴涨流量，一边是业务方的满心欢喜，一边就是工程师的烦恼和压力了。
也许是一个受欢迎的功能上线了，或者是某个社会活动导致流量爆发，系统开始出现高延迟，磁盘 IO 不够用了。
也许是 DB 第一个倒下，也许是 RPC 系统第一个倒下……
呃，大神可能会说，我艹，RPC 系统第一个倒下还搞个屁啊，赶紧倒闭算了。</p>
<p>核心的问题就是，在现有性能下面，在面临可能的大流量冲击时候，如何做到不慌不忙，能够 handle 住突如其来的流量？</p>
<h2 id="设定容量目标">设定容量目标</h2>
<p>在解决这个问题之前，我们得先考虑清楚，我们到底要多强的流量处理能力。
如果今天我们只是一个两三台服务器的小团队，却企图设计一个能够抗住 1 亿 pv 访问的系统，
显然是不现实的，至少是不经济的。</p>
<p>衡量系统容量的指标可以简化为在什么流量下面，提供什么样的可用性保证。
一个实际的样例是，在 1 亿 pv 下面，提供 99.99% 的可用性，
其可用性的评判标准是「服务器在 200ms 内返回正确的数据」。</p>
<p>这里有一个重要的概念，可用性保证，术语是服务等级协议（SLA）。
这个指标可以从大部分标准云供应商的标准条款里看到，比如我司机房供应商提供的可用性保证是 99.9%。
阿里云 ECS 的 SLA 是「99.95%」，统计周期是 1 个月
（如果故障时间低于 5 min，不计入故障时间，云供应商都这样，特别霸权）。</p>
<p>一个对 SLA 的直观认识是（具体数据来自 <a href="https://en.wikipedia.org/wiki/High_availability#Percentage_calculation">High availability - Wikipedia, the free encyclopedia</a>）：</p>
<ul>
<li>99.0% 意味着一年有 87 天不可用</li>
<li>99.5% 意味着一年 1.83 天不可用</li>
<li>99.9% 意味着一年 8.76 小时不可用</li>
<li>99.99% 意味着一年 52.56 分钟不可用</li>
<li>99.999% 意味着一年 5 分 15 秒不可用，这是高可用的一般标准</li>
</ul>
<p>设定越高的 SLA 的成本越高，具体 SLA 的设定是成本、收益、期望的平衡。
不同的业务需要的 SLA 也不一样，一般认为 99.9% 基本可用，99.99% 可用性较高，
99.999% 为高可用。</p>
<p>有些云供应商号称 8 个 9，9 个 9，那往往都是对于存储服务里面的数据不丢失这个指标。
除了忽悠忽悠人，这个 SLA 没什么用的。</p>
<h2 id="测量">测量</h2>
<p>做一件伟大事情时候，先有目标，下一步如果是迈出脚步出去闯荡，那么往往换来的是一个身心疲惫的自己。
更稳当的做法是，先摸摸清楚，自己有几把刷子，是不是还要再练练，有没有资格上战场。
没有 Profiling，就是瞎子，根本不用谈优化和容量规划。</p>
<p>对于一般的业务场景而言，常见的测量指标分为三类：</p>
<ul>
<li>服务器的硬件指标（CPU、内存、硬盘 IO、硬盘容量、网络）</li>
<li>服务的软件指标（QPS / latency / pool）</li>
<li>业务的数据指标（核心业务指标，比如注册数，核心动作次数）</li>
</ul>
<p>我司的实践情况是这样的，我们使用 Zabbix 测量服务器，用自己设计的系统收集服务数据，使用 Grafana 呈现。
后者被设计到 RPC 系统内部，数据是全量收集。
我司在业务层面的数据监控做的还不足，这种不足不仅仅体现在数据的全面性上面，还体现在相关成员（比如产品汪）对数据的利用率上面。</p>
<p>除了测量线上的实施数据，了解某个设施的性能极限也是很重要，目前常见的测量方式是：</p>
<ul>
<li>模拟流量进行测试</li>
<li>在线上进行测试，并实时跟踪进展情况，出现异常时候，停止流量切入</li>
<li>从线上引入流量到测试环境进行测试</li>
</ul>
<p>我发现，第一种方法往往不准，第三种方法对于小团队来说，成本太高。第二种方法是最粗暴和有效的。</p>
<h2 id="预警和提醒">预警和提醒</h2>
<p>仅仅知道当前系统的性能表现是不足的，重要的如何将这些数据利用起来，对未来系统增长进行预估。
流量增长 vs 资源消耗，这个曲线大部分情况是线性的，有些情况确实指数增长的。</p>
<p>常见的做法是，给核心指标设置一个阈值（比如 80% 磁盘使用率，40% 磁盘 IO 利用率），当监控的数据到达这个阈值时候。
就必须进行容量扩充，进行负载均衡。</p>
<p>一个从运维同学身上学到的是，提前采购一些设备放到机房里面，比如硬盘、内存，别到时候供应商来不及供货。
必要库存可以降低 MTBF。</p>
<p>除了设定阈值报警，应当定期跑一些脚本获得数据。定期检查报警系统，避免报警系统失效。</p>
<h2 id="必选项---scalable">必选项 - Scalable</h2>
<p>上文写到，「必要时候进行容量扩充，进行负载均衡」。
这点的提出，意味这需要<strong>保证基础设施是可扩展的，支持负载均衡，支持硬件扩容</strong>。</p>
<p>Web 系统比较容易做到横向扩容，使用 Nginx / LVS 等负载均衡即可。
中间件服务一般也是在设计时候就考虑了扩展。（什么？你们家 RPC 系统设计调用不支持扩展？什么脑残设计？！）</p>
<p>DB 级别的服务，往往就要花一些心思了，一些技术（比如 MySQL）想要做到横向扩展，
需要进行提前设计。而一些设施虽然容易进行扩展，比如 ES / Kafka 等现代化设施，
但在部署的时候仍然要进行一些提前准备。</p>
<p>除了提前做好 Scalable，还有几个和部署相关的 tips 可以供参考：</p>
<ul>
<li>使用工具：自动化部署，现在有太多工具可以供选择，比如 ansible 就是一个很好的工具</li>
<li>automatic everything：避免登录服务器操作才能保证未来自动化</li>
<li>工程化：用最佳实践去维护部署系统，用工程化的态度去写部署代码</li>
<li>保持同质，避免花样：避免使用 shell 级别的操作原语操作部署系统，使用预设的 module 去操作</li>
</ul>
<h2 id="end">End</h2>
<p>好了，现在去预测一下当大流量来临之际，你的服务会在哪些环节失败。
想不出来的话，就一点点去测量各个环节性能，然后做一把容量规划吧。</p>
<p>调优和增加容量，这是两个手段，这两个手段互相作用，互相影响。使用时候需要根据成本和收益进行选择。</p>
<p>关于容量规划的更多细节，可以看看 <a href="https://book.douban.com/subject/4200645/">Web容量规划的艺术 (豆瓣)</a>
这里看看。只是这本书写在 2010 年，并且作者介绍的过于传统运维视角一些。</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
